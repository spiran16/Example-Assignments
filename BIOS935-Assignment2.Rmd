---
title: "Homework 2"
author: '...'
date: "1/28/2021"
output:
  pdf_document: default
  html_document: default
subtitle: BIOS 635
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, include=TRUE,
                      fig.width = 10, fig.height = 5)
```

```{r packages, echo=TRUE}
library(tidyverse)
library(broom)
library(gtsummary)
library(flextable)
library(gt)
library(caret)
library(GGally)
library(e1071)
```

# Introduction
In this assignment you will practice using some basic machine learning methods and concepts discussed so far in lecture to develop prediction algorithms from real-world public health datasets.  You will predict a continuous outcome first, followed by a binary outcome ("Yes" or "No), using K-nearest neighbor, linear regression, and logistic regression

# 1
## Setup
In the first part, you will work with cancer mortality data in the United States at the county level from 2010-2016, with demographic information on the counties from 2013 US Census estimates.

The outcome of interest in the data is mean yearly per capita (100,000 people) cancer mortalities from 2010-2016, denoted `TARGET_deathRate` in the dataset (`cancer_reg.csv`).  So more info on the dataset in the docs folder.  

## A
First, let's look at summary statistics of the variables of interest in the data using the function `tbl_summary` in the `gtsummary` package.  Be sure to print the table as a `flextable` using the function `as_flex_table`.  Specifically:

- First, create variable `deathrate_vs_median` in dataset after reading in CSV
  - `deathrate_vs_median`="No" if `TARGET_deathRate`< `median(TARGET_deathRate)`
  - ="Yes" otherwise
- Provide stats for the following variables:
  -`TARGET_deathRate`, `medIncome`, `povertyPercent`, `MedianAge`, `PctPrivateCoverage`, `PctPublicCoverage`, `PctWhite`, `PctBlack`, `PctAsian`, `PctOtherRace`
  - **NOTE**: Don't remove variables from dataset to only those marked above.  Only use functions in `gtsummary` to remove variables from table (see `include` argument)
  - Group the summary statistics by `deathrate_vs_median`
  - Include sample size $N$ using `add_n`
  - Add p-values from one-way ANOVA test for differences in variables between "No" and "Yes" groups of `TARGET_deathRate`
  - For all variables, provide mean and standard deviation (SD) as statistics
  - Add a gray background to the cells in the row corresponding to `TARGET_deathRate`
    - **Hint**: Look at changing row/column background color in `flextable` package after using
    `as_flex_table` function
  - Also, bold text in header row after using `as_flex_table`

```{r 1a}
# Set up data
setwd("C:/Users/Saifa/Dropbox/Notes/UNC/Spring 2021/Machine Learning/Assignment 2")
cancer_reg <- read_csv("cancer_reg.csv")
cancer_reg$deathrate_vs_median <- ifelse(cancer_reg$TARGET_deathRate < median(cancer_reg$TARGET_deathRate), "No", "Yes")

#Summary Statistics 
summary <- 
  cancer_reg %>%
  select(TARGET_deathRate ,medIncome, povertyPercent, MedianAge, PctPrivateCoverage, PctPublicCoverage, PctWhite, PctBlack, PctAsian, PctOtherRace, deathrate_vs_median) %>%
  tbl_summary(
    by = deathrate_vs_median,
    statistic = list((all_continuous()~ "{mean} ({sd})")))
summary <- add_n(summary)
summary <- add_p(summary, test = list(all_continuous() ~ "aov"), group = deathrate_vs_median)

summary <- as_flex_table(summary)
summary <- bg(summary, bg = "gray", part = 'body')
summary <- bold(summary, part = 'header')

summary

```

## B
Now, let's do some data visualization.  

Let's look at some 2-dimensional scatterplots of some of the above variables to assess correlation.  Specifically, recreate the following matrix of scatterplots:

- Look at the following variables
  - Use `ggpairs` from the `GGally` package:     
    - https://www.r-graph-gallery.com/199-correlation-matrix-with-ggally.html
  - `medIncome`, `povertyPercent`, `PctPrivateCoverage`, `PctPublicCoverage`
  - Color points by `deathrate_vs_median`
  - Provide some interpretation of the relationships you see in the figure.  Specifically:
    - Are there variables that have high correlations?
      - Do these high correlations make sense conceptually?
    - Compare the distributions of the variables between the two mortality rate groups (see diagonal).

```{r 1b, warning = F, message=F }
ggpairs(cancer_reg, columns = c("medIncome", "povertyPercent", "PctPrivateCoverage", "PctPublicCoverage"), ggplot2::aes(color=deathrate_vs_median))



```


Based on the figure, all variables selected, poverty percentage, private health care coverage, and government-provided health coverage, correlate highly with the median death rate. This does not make conceptual sense to me. Correlations are not appropriate to analyze these data. Based on the diagonal, it seems that the individual variables are normally distributed with some skewness.



## C
Now, let's begin to create our prediction algorithms for `TARGET_deathRate`.  First, we will start with using K-nearest neighbor (KNN).

Let's consider the features included in our summary statistics table (`TARGET_deathRate`, `medIncome`, `povertyPercent`, `MedianAge`, `PctPrivateCoverage`, `PctPublicCoverage`, `PctWhite`, `PctBlack`, `PctAsian`, `PctOtherRace`).  

- First, we will split our data into separate training and testing sets (60% in training and 40% in testing) randomly.  
- Next, train a KNN algorithm on the training dataset.
  - Use `train` function in `caret` function (see lecture slides).  Use `tuneLength`=20 and center and scale the features (see `preProcess` argument).
  - Leave everything else at default.  What is the "best" tuning parameter value chosen for parameter $k$?
  What criteria is used by R to select this "best" parameter?
  - Plot the RMSE for each considered value of $k$ during the tuning process.  What does $k$ represent based on the plot (**Hint**: see lecture slides and x-axis of plot)
- Lastly, test your algorthim at this "best" tuning parameter value on the test set.  Print out the test set performance based on RMSE, $R^2$, and MAE using `flextable`

```{r 1c}
set.seed(12) # Setting seed for reproducibility

#Train and test data
cancer_reg_cd <- cancer_reg %>% 
      select(`TARGET_deathRate`, `medIncome`, `povertyPercent`, `MedianAge`, `PctPrivateCoverage`,              `PctPublicCoverage`, `PctWhite`, `PctBlack`, `PctAsian`, `PctOtherRace`)

cd <- createDataPartition(cancer_reg_cd$TARGET_deathRate, p=0.6, list = FALSE)
cd_train <- cancer_reg_cd[cd,]
cd_test <- cancer_reg_cd[-cd,]

# Train KNN algorithm
#cd_train <- preProcess(cd_train,method = c("center", "scale"))
knnFit <- train(TARGET_deathRate ~ ., data = cd_train, method = "knn", tuneLength = 20)
knnFit
plot(knnFit)

#Fit the test data
knnFittest <- train(TARGET_deathRate ~ ., data = cd_test, method = "knn", tuneLength = 20)
flextable(knnFittest$results[,1:4])

```


- The "best" tuning parameter value chosen for parameter $k$ is 43. 
- R takes a determines the "best" tuning parameter based on a combination of the lowest RMSE, highest $R^2$, and lowest MAE. In other words, R looks for the parameter that explains the most variance and produces low error. 
- Based on the plot, $k$ represents the number of nearest neighbors.



## D
### I
Let's next move to a linear regression model for prediction.  We consider the same features listed in 1c with the same outcome variable.

- Use the same training and testing sets created in 1c
- Train a linear regression algorithm with all of the above features.  Print out the following results:
  - Coefficient estimate table from `summary` function (estimate, standard error, test statistic, p-value)
    - Create this table using the `tidy` function from `broom` and print out using `flextable`
  - Evaluate the following assumptions using the corresponding visual
    - 1. Homoskedasicity (fitted value by residual plot)
    - 2. Normality (QQ plot of residuals vs theoretical normal distribution)
  - One may argue that normally distributed residuals are not a concern for this dataset.  Why?
  - One common belief in regression is that your **outcome** is assumed to be normally distributed.  Why is
  this incorrect?

### II
- Test the algorithm developed in the previous step on the test dataset.  Print out the following in a `flextable`
  - Test set RMSE, $R^2$, adjusted $R^2$, and MAE
- In a separate `flextable`, print out these same metrics based on the performance in the training set
  - Evaluate the differences between the training and testing performance
- Based on your plots in 1b, do you have any concerns about collinearity?  If so, how would you change the set of feature variable used to fix this concern?  How did you choose this set?
  - **Note**: you don't need to actually re-run the regression analysis with this reduced set of features


```{r 1d}
#PART I

#Fit the linear model in train data set
lm_fit <- lm(TARGET_deathRate ~., data = cd_train)

train <- tidy(lm_fit) %>%
  mutate(p.value=ifelse(p.value<0.005, "<0.005", 
                        as.character(round(p.value, 2)))) %>%
  flextable()
train

#Test assumptions
#par(mfrow = c(2, 2))
#plot(lm_fit)

#############################
#PART II
m_fit <- lm(TARGET_deathRate ~., data = cd_test)
test <- tidy(m_fit) %>%
  mutate(p.value=ifelse(p.value<0.005, "<0.005", 
                        as.character(round(p.value, 2)))) %>%
  flextable()
#test

#The table for test data
test
```

###### Part I
Based on the residuals vs fitted plot, the data fits the assumption of Homoskedasicity. The values appear to be scattered evenly without any clear trends. There are outliers present that need to be addressed. Based on the QQ plot, the resdiuals appear to be normally distributed (not the best), with the exception of outliers. 
The normally distributed residuals are not a concern for this dataset, because they follow the assumptions of a linear model. Your **outcome** variable is not always normally distributed is incorrect, because not all **outcome**variables follow a normal distribution. An **outcome** varaible can be binary or logistic.


###### Part II
The significance of the regression coefficients changes in the test data set. For example, the variable "medIncome" has a p-value of 0.00 in the train data set, but a p-value in the test data set is 0.42. However, the regression coefficients are relatively the same in the train and the test data set. Based on the graph in 1b, multi-collinearity is definitely an issue here. The high correlations between all of the varaibles are inducing linearly dependent results. Using different variables with smaller correlation values or using a step-wise regression procedure would help.


# 2
## Setup
In the second part, you will work with diabetes incidence data in the US, composed of Native American, female hospital patients at 21 years old.

The outcome of interest, `Outcome` in the data is binary indicator if the patient has a diagnosis of diabetes (0 = "No", 1 = "Yes").  You will try to predict this outcome based on patient traits as features.  See the docs folder for more information.  The dataset is called `diabetes_data.csv`.

## A
First, let's look at summary statistics of the variables of interest in the data using the function `tbl_summary` in the `gtsummary` package.  Be sure to print the table as a `flextable` using the function `as_flex_table`.  Specifically:

- Provide stats for the following variables:
  - `Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`, `Age`
  - **NOTE**: Don't remove variables from dataset to only those marked above.  Only use functions in `gtsummary` to remove variables from table (see `include` argument)
  - Group the summary statistics by `Outcome`
  - Include sample size $N$ using `add_n`
  - Add p-values from one-way ANOVA test for differences in variables between groups of `Outcome`
  - For all variables, provide mean and standard deviation (SD) as statistics
  - Also, bold text in header row after using `as_flex_table`

```{r 2a}
#Load the data
diabetes_data <- read_csv("diabetes.csv")

#Data Summary
summary2 <- 
  diabetes_data %>%
  select(`Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`, `Age`,`Outcome`) %>%
  tbl_summary(
    by = Outcome,
    statistic = list((all_continuous()~ "{mean} ({sd})")))

summary2 <- add_n(summary2)
summary2 <- add_p(summary2, test = list(all_continuous() ~ "aov"), group = Outcome)
summary2 <- as_flex_table(summary2)
summary2 <- bold(summary2, part = 'header')

summary2
```

## B
Now, let's begin to create our prediction algorithms for `Outcome`.  First, we will start with using K-nearest neighbor (KNN).

Let's consider the features included in our summary statistics table (`Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`, `Age`).  

- First, we will split our data into separate training and testing sets (60% in training and 40% in testing) randomly.  
- Next, train a KNN algorithm on the training dataset.
  - Use `train` function in `caret` function (see lecture slides).  Use `tuneLength`=20 and center and scale the features (see `preProcess` argument).
  - Leave everything else at default.  What is the "best" tuning parameter value chosen for parameter $k$?
  What criteria is used by R to select this "best" parameter?
  - Plot the Prediction Accuracy for each considered value of $k$ during the tuning process.  What does $k$ represent based on the plot (**Hint**: see lecture slides and x-axis of plot)
- Lastly, test your algorithm at this "best" tuning parameter value on the test set.  Print out the test set performance based on Prediction Accuracy, Sensitivity, Specificity, PPV, and NPV using `flextable`.
  - **Hint**: Use `confusionMatrix` function in `caret` package.  Then convert to data frame to print as
  `flextable`

```{r 2b}

set.seed(12) # Setting seed for reproducibility
#Split data into train and test data
diabetes_data$Outcome <- as.factor(diabetes_data$Outcome) # Making the outcome variable a 2 level factor
diabetes_data_cd <- diabetes_data %>% 
      select(`Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`,          `Age`,`Outcome`)
cd_dd <- createDataPartition(diabetes_data_cd$Outcome, p=0.6, list = FALSE)
cd_traindd <- diabetes_data_cd[cd_dd,]
cd_testdd <- diabetes_data_cd[-cd_dd,]

# Train KNN algorithm
#cd_train <- preProcess(cd_train,method = c("center", "scale"))

knnFit2 <- train(Outcome ~ ., data = cd_traindd, method = "knn", tuneLength = 20)
knnFit2


# knn on Test Data
knnFittest2 <- train(Outcome ~ ., data = cd_testdd, method = "knn", tuneLength = 20)

# Make the Confusion Matrix
cd_testdd$prob_diabetes <-
  predict(knnFittest2, newdata=cd_testdd)

cm <- confusionMatrix(data = cd_testdd$prob_diabetes,
                reference = cd_testdd$Outcome,
                positive = "1")

df <- data.frame(c(cm$overall[1], cm$byClass[1], cm$byClass[2], cm$byClass[3], cm$byClass[4]))
colnames(df) <- "Data"

table <- df %>%
  as.data.frame() %>%
  add_rownames() %>%
  flextable()
  
# Table of values based on test data set
table

```
#### Answers to 2b
- The "best" tuning parameter value chosen for parameter $k$ is 25.
- R looks for the parameter that produces the highest accuracy rate and the highest Kappa value, or the classification accuracy, taking random chance into account. 
- Based on the plot, $k$ represents the number of nearest neighbors.



## C
Finally, we will end with using logistic regression.  We consider the same features listed in 2b with the same outcome variable.

- Train a logistic regression algorithm with all of the above features.  Print out the following results:
  - Coefficient estimate table from `summary` function (estimate, standard error, test statistic, p-value)
    - Create this table using the `tidy` function from `broom` and print out using `flextable`
  - Print out the test set performance based on Prediction Accuracy, Sensitivity, Specificity, PPV, and NPV using `flextable`.
    - **Hint**: Use `confusionMatrix` function in `caret` package.  Then convert to data frame to print as
  `flextable`

```{r 2c}
set.seed(12) # Setting seed for reproducibility
# Using the same train and test data from 2b

# Fit logistic regression model
lm_fit <- glm(formula = Outcome~.,
              data = cd_traindd,
              family = binomial())

#Create table
sum <- summary(lm_fit)
tidy(lm_fit) %>%
mutate(p.value=ifelse(p.value<0.005, "<0.005", 
                        as.character(round(p.value, 2)))) %>%
  flextable()



# Using the test data set create flextable
cd_testdd$prob_diabetes_lm <-
  predict(lm_fit, newdata=cd_testdd)


cd_testdd <-
  cd_testdd %>%
  mutate(pred_diabetes_lm = 
           relevel(factor(ifelse(prob_diabetes_lm>0.5, "1", "0")),
                   ref = "0"))

cm <- confusionMatrix(data = cd_testdd$pred_diabetes_lm,
                reference = cd_testdd$Outcome,
                positive = "1")
df <- data.frame(c(cm$overall[1], cm$byClass[1], cm$byClass[2], cm$byClass[3], cm$byClass[4]))
colnames(df) <- "Data"

table <- df %>%
  as.data.frame() %>%
  add_rownames() %>%
  flextable() 
  
# Table of values based on test data set
table

```
